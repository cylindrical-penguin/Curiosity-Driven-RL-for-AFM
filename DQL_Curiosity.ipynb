{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/adivatsavai/Adi/Curiosity RL/im2spec\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/ziatdinovmax/im2spec.git\n",
    "%cd im2spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.8.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import pygame\n",
    "\n",
    "import scipy\n",
    "import gdown\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from copy import deepcopy as dc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from im2spec.models import im2spec, spec2im\n",
    "from im2spec.utils import create_training_set, predict, loop_area, encode, decode, latent_gmm\n",
    "from im2spec.train_utils import trainer\n",
    "\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gdown https://drive.google.com/uc?id=1yrGXukGspctsSYrHn3grY_isQR2VFPLd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5 = h5py.File(r'BEPS_kyleSample_3um_0018.h5', 'r+')\n",
    "\n",
    "spec_val = h5['Measurement_000/Channel_000/Raw_Data-SHO_Fit_001/Spectroscopic_Values']\n",
    "\n",
    "\n",
    "amp = h5['Measurement_000/Channel_000/Raw_Data-SHO_Fit_000/Guess']['Amplitude [V]'].reshape(100,100,384)\n",
    "pha = h5['Measurement_000/Channel_000/Raw_Data-SHO_Fit_000/Guess']['Phase [rad]'].reshape(100,100,384)\n",
    "fre = h5['Measurement_000/Channel_000/Raw_Data-SHO_Fit_000/Guess']['Frequency [Hz]'].reshape(100,100,384)\n",
    "q = h5['Measurement_000/Channel_000/Raw_Data-SHO_Fit_000/Guess']['Quality Factor'].reshape(100,100,384)\n",
    "#r2 = h5['Measurement_000/Channel_001/Raw_Data-SHO_Fit_000/Guess']['R2 Criterion'].reshape(100,100,384)\n",
    "pola = (amp*np.cos(pha+2))*1E5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class environment(gym.Env):\n",
    "    def __init__(self, image, spectra, start = [50, 50], image_patch = 5):\n",
    "        super(environment, self).__init__()\n",
    "        self.image_patch = image_patch\n",
    "        self.radius = int((image_patch - 1)/2)+1\n",
    "        self.image = image\n",
    "        self.spectra = spectra\n",
    "        self.color = 255/(image.max() - image.min()) * image - 255/(image.max() - image.min()) * image.min()\n",
    "        self.num_rows = 100\n",
    "        self.num_columns = 100\n",
    "        self.pos_X = [start]\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        self.X.append(self.image[start[0]-int((self.image_patch-1)/2): start[0] + int((self.image_patch+1)/2), start[1]-int((self.image_patch-1)/2): start[1] + int((self.image_patch+1)/2)])\n",
    "        self.y.append(spectra[start[0], start[1]])\n",
    "        self.seen = np.zeros([100, 100])\n",
    "        self.pos = start\n",
    "        self.pos_X = [start]\n",
    "        \n",
    "        for i in range(self.radius):\n",
    "                for j in range(self.radius):\n",
    "                    self.seen[start[0]+i, start[1]+j] = 1\n",
    "                    self.seen[start[0]-i, start[1]+j] = 1\n",
    "                    self.seen[start[0]+i, start[1]-j] = 1\n",
    "                    self.seen[start[0]-i, start[1]-j] = 1\n",
    "        \n",
    "        \n",
    "        self.observation_space = spaces.Tuple((spaces.Discrete(self.num_rows), spaces.Discrete(self.num_columns)))\n",
    "        \n",
    "        pygame.init()\n",
    "        self.cell_size = 8\n",
    "        \n",
    "        self.screen = pygame.display.set_mode((self.num_columns * self.cell_size, self.num_rows * self.cell_size))\n",
    "        \n",
    "    \n",
    "    def step(self, action):\n",
    "        self.pos = action\n",
    "        if not [action[0], action[1]] in self.pos_X:\n",
    "            self.pos_X.append(action)\n",
    "            for i in range(self.radius):\n",
    "                for j in range(self.radius):\n",
    "                    self.seen[action[0]+i, action[1]+j] = 1\n",
    "                    self.seen[action[0]-i, action[1]+j] = 1\n",
    "                    self.seen[action[0]+i, action[1]-j] = 1\n",
    "                    self.seen[action[0]-i, action[1]-j] = 1\n",
    "            \n",
    "            ind = action\n",
    "            self.X.append(self.image[ind[0]-int((self.image_patch-1)/2): ind[0] + int((self.image_patch+1)/2), ind[1]-int((self.image_patch-1)/2): ind[1] + int((self.image_patch+1)/2)])\n",
    "            self.y.append(spectra[ind[0], ind[1]])\n",
    "                    \n",
    "    \n",
    "    def state(self, model):\n",
    "        pred_loop = predict(model, self.X[-1].reshape([1, 1, self.image_patch, self.image_patch])).reshape(64)\n",
    "        \n",
    "        reward = np.sum((pred_loop - self.y[-1])**2)\n",
    "        state = [self.pos[0], self.pos[1]]\n",
    "        state += list(self.X[-1].reshape(self.image_patch**2))\n",
    "        state += list(self.y[-1])\n",
    "        return(self.pos_X, np.array(self.X).reshape([len(self.X), 1, self.image_patch, self.image_patch]), np.array(self.y).reshape([len(self.y), 1, 64]), state, reward)\n",
    "    \n",
    "    def render(self, action):\n",
    "\n",
    "        self.screen.fill((255, 255, 255)) \n",
    "        \n",
    "        for row in range(self.num_rows):\n",
    "            for col in range(self.num_columns):\n",
    "                cell_left = col * self.cell_size\n",
    "                cell_top = row * self.cell_size\n",
    "                \n",
    "                pygame.draw.rect(self.screen, (0, 0, self.color[row, col]), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "                \n",
    "                if self.seen[row, col] == 1:\n",
    "                    pygame.draw.rect(self.screen, (0, self.color[row, col], 0), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "                \n",
    "                if [row, col] in self.pos_X:\n",
    "                    pygame.draw.rect(self.screen, (self.color[row, col], 0, 0), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "                \n",
    "                    \n",
    "                \n",
    "\n",
    "        pygame.display.update()\n",
    "\n",
    "            \n",
    "    def reset(self, start = [50, 50]):\n",
    "        self.pos_X = []\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        self.seen = np.zeros([100, 100])\n",
    "        self.X.append(self.image[start[0]-int((self.image_patch-1)/2): start[0] + int((self.image_patch+1)/2), start[1]-int((self.image_patch-1)/2): start[1] + int((self.image_patch+1)/2)])\n",
    "        self.y.append(spectra[start[0], start[1]])\n",
    "        self.seen = np.zeros([100, 100])\n",
    "        self.pos = start\n",
    "        self.pos_X = [start]\n",
    "        \n",
    "        for i in range(self.radius):\n",
    "                for j in range(self.radius):\n",
    "                    self.seen[start[0]+i, start[1]+j] = 1\n",
    "                    self.seen[start[0]-i, start[1]+j] = 1\n",
    "                    self.seen[start[0]+i, start[1]-j] = 1\n",
    "                    self.seen[start[0]-i, start[1]-j] = 1\n",
    "        \n",
    "        \n",
    "        self.observation_space = spaces.Tuple((spaces.Discrete(self.num_rows), spaces.Discrete(self.num_columns)))\n",
    "        \n",
    "        pygame.init()\n",
    "        self.cell_size = 8\n",
    "        \n",
    "        self.screen = pygame.display.set_mode((self.num_columns * self.cell_size, self.num_rows * self.cell_size))      \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, n_actions)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "\n",
    "            return policy_net(state).max(1).indices.view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randint(0, n_actions-1)]], device=device, dtype=torch.long)\n",
    "    \n",
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n",
    "\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 282.53265... Test loss: 279.21411\n",
      "Epoch: 1... Training loss: 256.07867... Test loss: 255.37231\n",
      "Epoch: 1... Training loss: 132.18156... Test loss: 133.96418\n",
      "Epoch: 1... Training loss: 74.02675... Test loss: 76.1176\n",
      "Epoch: 1... Training loss: 77.11907... Test loss: 80.4603\n",
      "Epoch: 1... Training loss: 55.25793... Test loss: 57.08502\n",
      "Epoch: 1... Training loss: 60.65109... Test loss: 63.49926\n",
      "Epoch: 1... Training loss: 49.31269... Test loss: 51.03321\n",
      "Epoch: 1... Training loss: 48.6919... Test loss: 50.99257\n",
      "Epoch: 1... Training loss: 47.02327... Test loss: 48.69957\n",
      "Epoch: 1... Training loss: 43.14386... Test loss: 44.77903\n",
      "Epoch: 1... Training loss: 36.51435... Test loss: 37.62475\n",
      "Epoch: 1... Training loss: 34.88717... Test loss: 35.95741\n",
      "Epoch: 1... Training loss: 31.1224... Test loss: 32.27818\n",
      "Epoch: 1... Training loss: 30.40655... Test loss: 31.13335\n",
      "Epoch: 1... Training loss: 28.95173... Test loss: 30.06375\n",
      "Epoch: 1... Training loss: 29.76359... Test loss: 30.10119\n",
      "Epoch: 1... Training loss: 29.18923... Test loss: 29.75173\n",
      "Epoch: 1... Training loss: 26.18217... Test loss: 26.37976\n",
      "Epoch: 1... Training loss: 24.6747... Test loss: 25.22881\n",
      "Epoch: 1... Training loss: 22.79211... Test loss: 22.77677\n",
      "Epoch: 1... Training loss: 23.75585... Test loss: 24.05136\n",
      "Epoch: 1... Training loss: 22.21359... Test loss: 22.14811\n",
      "Epoch: 1... Training loss: 20.55579... Test loss: 20.72273\n",
      "Epoch: 1... Training loss: 20.37629... Test loss: 20.49844\n",
      "Epoch: 1... Training loss: 20.4842... Test loss: 20.52844\n",
      "Epoch: 1... Training loss: 19.21279... Test loss: 19.32572\n",
      "Epoch: 1... Training loss: 17.918... Test loss: 17.90896\n",
      "Epoch: 1... Training loss: 18.01197... Test loss: 18.10299\n",
      "Epoch: 1... Training loss: 17.1659... Test loss: 17.03411\n",
      "Epoch: 1... Training loss: 17.13147... Test loss: 17.17278\n",
      "Epoch: 1... Training loss: 16.10449... Test loss: 15.96367\n",
      "Epoch: 1... Training loss: 15.70577... Test loss: 15.69789\n",
      "Epoch: 1... Training loss: 14.81219... Test loss: 14.80087\n",
      "Epoch: 1... Training loss: 14.3086... Test loss: 14.19755\n",
      "Epoch: 1... Training loss: 13.92158... Test loss: 13.9593\n",
      "Epoch: 1... Training loss: 13.98202... Test loss: 13.84664\n",
      "Epoch: 1... Training loss: 13.23453... Test loss: 13.26795\n",
      "Epoch: 1... Training loss: 13.1093... Test loss: 13.06022\n",
      "Epoch: 1... Training loss: 12.48972... Test loss: 12.49671\n",
      "Epoch: 1... Training loss: 12.35552... Test loss: 12.28428\n",
      "Epoch: 1... Training loss: 11.96661... Test loss: 11.9411\n",
      "Epoch: 1... Training loss: 11.71372... Test loss: 11.64787\n",
      "Epoch: 1... Training loss: 11.50263... Test loss: 11.40897\n",
      "Epoch: 1... Training loss: 11.04682... Test loss: 10.97993\n",
      "Epoch: 1... Training loss: 11.02203... Test loss: 10.99218\n",
      "Epoch: 1... Training loss: 10.96831... Test loss: 10.88716\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 10000\n",
    "TAU = 0.005\n",
    "LR = 1e-4\n",
    "\n",
    "start = [50, 50]\n",
    "image_patch = 5\n",
    "image, spectra = pola[:,:,0], pola[:,:,::2][:,:,0:64]\n",
    "radius = int((image_patch - 1)/2)\n",
    "\n",
    "env = environment(image, spectra, start = start, image_patch = image_patch)\n",
    "\n",
    "n_actions = (100 - 2*radius)**2\n",
    "n_observations = 2 + image_patch**2 + 64\n",
    "\n",
    "policy_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "\n",
    "model = im2spec((image_patch, image_patch), 64, 10)\n",
    "\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "pos_X, X, y, state, reward = env.state(model)\n",
    "model = trainer(model, X, y, X, y, num_epochs=1, savename=\"im2spec_lv{}\".format(10)).run()\n",
    "state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "env.render(start)\n",
    "for i in range(100):\n",
    "    action = select_action(state)\n",
    "    env.step([action.item()//(100 - 2*radius)+radius, action.item()%(100 - 2*radius)+radius])\n",
    "    \n",
    "    pos_X, X, y, observation, reward = env.state(model)\n",
    "        \n",
    "    model = trainer(model, X, y, X, y, num_epochs=1, savename=\"im2spec_lv{}\".format(10)).run()\n",
    "    reward = torch.tensor([reward], device=device)\n",
    "\n",
    "\n",
    "    next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "    # Store the transition in memory\n",
    "    memory.push(state, action, next_state, reward)\n",
    "\n",
    "    # Move to the next state\n",
    "    state = next_state\n",
    "\n",
    "    # Perform one step of the optimization (on the policy network)\n",
    "    optimize_model()\n",
    "\n",
    "    # Soft update of the target network's weights\n",
    "    # θ′ ← τ θ + (1 −τ )θ′\n",
    "    target_net_state_dict = target_net.state_dict()\n",
    "    policy_net_state_dict = policy_net.state_dict()\n",
    "    for key in policy_net_state_dict:\n",
    "        target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "    target_net.load_state_dict(target_net_state_dict)\n",
    "    env.render([action.item()//(100 - 2*radius)+radius, action.item()%(100 - 2*radius)+radius])\n",
    "    pygame.time.wait(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
